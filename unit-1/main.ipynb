{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552790bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implements unit 1 of the deep RL course\n",
    "\"\"\"\n",
    "import gym\n",
    "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
    "from pyvirtualdisplay import Display\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "\n",
    "def env_info(env_name):\n",
    "    \"\"\"\n",
    "    Print initial environment information\n",
    "    \"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    _ = env.reset()\n",
    "    for _ in range(20):\n",
    "        # Take a random action\n",
    "        action = env.action_space.sample()\n",
    "        print(\"Action taken:\", action)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            observation = env.reset()\n",
    "            print(\"Environment is reset\")\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "    print(\"___OBSERVATION SPACE___\")\n",
    "    print(\"Observation space shape:\", env.observation_space.shape)\n",
    "    print(\"Sample observation:\", env.observation_space.sample())\n",
    "\n",
    "    print(\"___ACTION SPACE___\")\n",
    "    print(\"Action space shape:\", env.action_space.n)\n",
    "    print(\"Action space sample:\", env.action_space.sample())\n",
    "\n",
    "\n",
    "def train(env_name, batch_size=16, num_steps=1000000):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \"\"\"\n",
    "\n",
    "    # Vectorized environment, so we can batch examples during training\n",
    "    env = make_vec_env(env_name, n_envs=batch_size)\n",
    "    model = PPO(\n",
    "        policy=\"MlpPolicy\",\n",
    "        env=env,\n",
    "        n_steps=1024,\n",
    "        batch_size=64,\n",
    "        n_epochs=4,\n",
    "        gamma=0.999,\n",
    "        gae_lambda=0.98,\n",
    "        ent_coef=0.01,\n",
    "        verbose=1,\n",
    "    )\n",
    "    model.learn(total_timesteps=num_steps)\n",
    "    model_name = f\"ppo-{env_name}\"\n",
    "    model.save(model_name)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(env_name, model):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model\n",
    "    \"\"\"\n",
    "    env = gym.make(env_name)\n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        model, env, n_eval_episodes=10, deterministic=True\n",
    "    )\n",
    "    print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward}\")\n",
    "\n",
    "\n",
    "def publish(model, env_name, model_name):\n",
    "    \"\"\"\n",
    "    Publish the model to the huggingface hub (requires login through the CLI)\n",
    "    \"\"\"\n",
    "    repo_id = \"arkadyark/deep-rl-course-unit-1\"\n",
    "    env_id = env_name\n",
    "    eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "    model_architecture = \"PPO\"\n",
    "    commit_message = \"Push LunarLander-v2 model\"\n",
    "\n",
    "    package_to_hub(\n",
    "        model,\n",
    "        model_name=model_name,\n",
    "        model_architecture=model_architecture,\n",
    "        env_id=env_id,\n",
    "        eval_env=eval_env,\n",
    "        repo_id=repo_id,\n",
    "        commit_message=commit_message,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b11a503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f521c57cdc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fbf224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken: 3\n",
      "Action taken: 3\n",
      "Action taken: 2\n",
      "Action taken: 3\n",
      "Action taken: 1\n",
      "Action taken: 2\n",
      "Action taken: 2\n",
      "Action taken: 2\n",
      "Action taken: 3\n",
      "Action taken: 1\n",
      "Action taken: 2\n",
      "Action taken: 2\n",
      "Action taken: 1\n",
      "Action taken: 3\n",
      "Action taken: 1\n",
      "Action taken: 0\n",
      "Action taken: 0\n",
      "Action taken: 3\n",
      "Action taken: 2\n",
      "Action taken: 2\n",
      "___OBSERVATION SPACE___\n",
      "Observation space shape: (8,)\n",
      "Sample observation: [-0.04787325 -0.836816   -0.3753528  -0.04970386  0.41284412  0.2904583\n",
      "  0.636347   -1.0349195 ]\n",
      "___ACTION SPACE___\n",
      "Action space shape: 4\n",
      "Action space sample: 0\n"
     ]
    }
   ],
   "source": [
    "env_name = \"LunarLander-v2\"\n",
    "model_name = f\"arkadyark/{env_name}\"\n",
    "env_info(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0b5007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.7     |\n",
      "|    ep_rew_mean     | -198     |\n",
      "| time/              |          |\n",
      "|    fps             | 9032     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.8         |\n",
      "|    ep_rew_mean          | -185         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4801         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066265482 |\n",
      "|    clip_fraction        | 0.0728       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.000734    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 691          |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.4        |\n",
      "|    ep_rew_mean          | -139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4149        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006224025 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.00354    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 480         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.9        |\n",
      "|    ep_rew_mean          | -94.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3888        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826788 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.0133     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 850         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 95.5       |\n",
      "|    ep_rew_mean          | -89.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3719       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 88         |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00969607 |\n",
      "|    clip_fraction        | 0.0878     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | -0.0145    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 202        |\n",
      "|    n_updates            | 16         |\n",
      "|    policy_gradient_loss | -0.00722   |\n",
      "|    value_loss           | 488        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 103         |\n",
      "|    ep_rew_mean          | -68.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3613        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009430534 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.00257     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -48.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3559        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466209 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -9.62e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | -35.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3497        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010118674 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -4.29e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | -28.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3432        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009313744 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 131       |\n",
      "|    ep_rew_mean          | -21.5     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 3352      |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 195       |\n",
      "|    total_timesteps      | 655360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0053851 |\n",
      "|    clip_fraction        | 0.0482    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.16     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 161       |\n",
      "|    n_updates            | 36        |\n",
      "|    policy_gradient_loss | -0.00224  |\n",
      "|    value_loss           | 494       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | -5.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3194        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006739664 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.000183    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 335         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    value_loss           | 598         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | -4.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2949        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007501346 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.00424     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 597         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 416         |\n",
      "|    ep_rew_mean          | 7.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2731        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005710928 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 437         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 632          |\n",
      "|    ep_rew_mean          | 36.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2520         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 363          |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079350425 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 96.1         |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 256          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 731          |\n",
      "|    ep_rew_mean          | 54.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2355         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 417          |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052548433 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 819         |\n",
      "|    ep_rew_mean          | 71.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2225        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004533704 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = train(env_name, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c78425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/ark/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "notebook_login()\n",
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fa290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mâ„¹ This function will save, evaluate, generate a video of your agent,\n",
      "create a model card and push everything to the hub. It might take up to 1min.\n",
      "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ark/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path '/tmp/tmpfn09c9nw/arkadyark' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
      "/home/ark/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    },
    {
     "ename": "ContextException",
     "evalue": "Could not create GL context",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContextException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m, in \u001b[0;36mpublish\u001b[0;34m(model, env_name, model_name)\u001b[0m\n\u001b[1;32m     82\u001b[0m model_architecture \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m commit_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPush LunarLander-v2 model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 85\u001b[0m \u001b[43mpackage_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_architecture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_architecture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/huggingface_sb3/push_to_hub.py:375\u001b[0m, in \u001b[0;36mpackage_to_hub\u001b[0;34m(model, model_name, model_architecture, env_id, eval_env, repo_id, commit_message, is_deterministic, n_eval_episodes, token, video_length, logs)\u001b[0m\n\u001b[1;32m    370\u001b[0m mean_reward, std_reward \u001b[38;5;241m=\u001b[39m _evaluate_agent(\n\u001b[1;32m    371\u001b[0m     model, eval_env, n_eval_episodes, is_deterministic, tmpdirname\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Step 4: Generate a video\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m \u001b[43m_generate_replay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplay_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_deterministic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpdirname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Step 5: Generate the model card\u001b[39;00m\n\u001b[1;32m    378\u001b[0m generated_model_card, metadata \u001b[38;5;241m=\u001b[39m _generate_model_card(\n\u001b[1;32m    379\u001b[0m     model_architecture, env_id, mean_reward, std_reward\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/huggingface_sb3/push_to_hub.py:136\u001b[0m, in \u001b[0;36m_generate_replay\u001b[0;34m(model, eval_env, video_length, is_deterministic, local_path)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmpdirname:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Step 1: Create the VecVideoRecorder\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     env \u001b[38;5;241m=\u001b[39m VecVideoRecorder(\n\u001b[1;32m    129\u001b[0m         eval_env,\n\u001b[1;32m    130\u001b[0m         tmpdirname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     )\n\u001b[0;32m--> 136\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     lstm_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((env\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py:68\u001b[0m, in \u001b[0;36mVecVideoRecorder.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvObs:\n\u001b[1;32m     67\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvenv\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_video_recorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py:80\u001b[0m, in \u001b[0;36mVecVideoRecorder.start_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m base_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_folder, video_name)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_recorder \u001b[38;5;241m=\u001b[39m video_recorder\u001b[38;5;241m.\u001b[39mVideoRecorder(\n\u001b[1;32m     77\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, base_path\u001b[38;5;241m=\u001b[39mbase_path, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_id}\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_recorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecording \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:132\u001b[0m, in \u001b[0;36mVideoRecorder.capture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapturing video frame: path=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    131\u001b[0m render_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mansi\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mansi_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 132\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async:\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:98\u001b[0m, in \u001b[0;36mDummyVecEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mGym environment rendering. If there are multiple environments then\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mthey are tiled together in one image via ``BaseVecEnv.render()``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param mode: The rendering type.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrender(mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/gym/envs/box2d/lunar_lander.py:388\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassic_control\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rendering\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m rendering\u001b[38;5;241m.\u001b[39mViewer(VIEWPORT_W, VIEWPORT_H)\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/gym/envs/classic_control/rendering.py:27\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Cannot import pyglet.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Error occurred while running `from pyglet.gl import *`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     )\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/gl/__init__.py:244\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pyglet_doc_run \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyglet.window\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _sys\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;129;01mand\u001b[39;00m _pyglet\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshadow_window\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# trickery is for circular import\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     _pyglet\u001b[38;5;241m.\u001b[39mgl \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/window/__init__.py:1891\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pyglet_doc_run:\n\u001b[1;32m   1890\u001b[0m     pyglet\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m-> 1891\u001b[0m     \u001b[43mgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_shadow_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/gl/__init__.py:220\u001b[0m, in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Window\n\u001b[0;32m--> 220\u001b[0m _shadow_window \u001b[38;5;241m=\u001b[39m \u001b[43mWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m _shadow_window\u001b[38;5;241m.\u001b[39mswitch_to()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyglet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/window/xlib/__init__.py:171\u001b[0m, in \u001b[0;36mXlibWindow.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_handlers[message] \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXlibWindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _can_detect_autorepeat\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_detect_autorepeat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/window/__init__.py:594\u001b[0m, in \u001b[0;36mBaseWindow.__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, file_drops, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    591\u001b[0m     config \u001b[38;5;241m=\u001b[39m screen\u001b[38;5;241m.\u001b[39mget_best_config(config)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context:\n\u001b[0;32m--> 594\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# Set these in reverse order to above, to ensure we get user preference\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context \u001b[38;5;241m=\u001b[39m context\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/gl/xlib.py:204\u001b[0m, in \u001b[0;36mXlibCanvasConfig13.create_context\u001b[0;34m(self, share)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, share):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglx_info\u001b[38;5;241m.\u001b[39mhave_extension(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLX_ARB_create_context\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mXlibContextARB\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m XlibContext13(\u001b[38;5;28mself\u001b[39m, share)\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/gl/xlib.py:314\u001b[0m, in \u001b[0;36mXlibContext13.__init__\u001b[0;34m(self, config, share)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, share):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXlibContext13\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglx_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/envs/deep-rl-course-unit-1/lib/python3.9/site-packages/pyglet/gl/xlib.py:218\u001b[0m, in \u001b[0;36mBaseXlibContext.__init__\u001b[0;34m(self, config, share)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglx_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_glx_context(share)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglx_context:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# TODO: Check Xlib error generated\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m gl\u001b[38;5;241m.\u001b[39mContextException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not create GL context\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_have_SGI_video_sync \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mglx_info\u001b[38;5;241m.\u001b[39mhave_extension(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLX_SGI_video_sync\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_have_SGI_swap_control \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mglx_info\u001b[38;5;241m.\u001b[39mhave_extension(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLX_SGI_swap_control\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mContextException\u001b[0m: Could not create GL context"
     ]
    }
   ],
   "source": [
    "publish(model, env_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ba164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
